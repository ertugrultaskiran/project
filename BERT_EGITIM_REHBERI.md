# ğŸš€ BERT Model EÄŸitim Rehberi

## ğŸ“‹ SeÃ§enekler

BERT modelini 3 farklÄ± yolla eÄŸitebilirsiniz:

---

## 1ï¸âƒ£ Jupyter Notebook (Ã–nerilen - AdÄ±m AdÄ±m)

### Avantajlar:
- âœ… Her adÄ±mÄ± gÃ¶rebilirsiniz
- âœ… Ara sonuÃ§larÄ± inceleyebilirsiniz
- âœ… Ä°stediÄŸiniz yerde durup devam edebilirsiniz

### KullanÄ±m:
```bash
jupyter notebook src/03_bert_transformer.ipynb
```

ArdÄ±ndan browser'da notebook'u aÃ§Ä±n ve hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n.

---

## 2ï¸âƒ£ Python Script (Kolay - Otomatik)

### Avantajlar:
- âœ… Tek komutla baÅŸlatÄ±p bitirirsiniz
- âœ… Terminal'de ilerlemeyi gÃ¶rebilirsiniz
- âœ… Daha hÄ±zlÄ± ve pratik

### KullanÄ±m:
```bash
python src/train_bert.py
```

Script otomatik olarak:
1. Veriyi yÃ¼kler
2. BERT modelini indirir
3. EÄŸitimi baÅŸlatÄ±r
4. En iyi modeli kaydeder
5. Test sonuÃ§larÄ±nÄ± gÃ¶sterir

---

## 3ï¸âƒ£ Google Colab (GPU Yoksa - ÃœCRETSÄ°Z GPU!)

### Avantajlar:
- âœ… Ãœcretsiz GPU kullanÄ±mÄ±
- âœ… Kendi bilgisayarÄ±nÄ±z yormaz
- âœ… Ã‡ok daha hÄ±zlÄ± (~10-20x)

### AdÄ±mlar:

1. **Google Colab'a Git:**
   - https://colab.research.google.com

2. **Notebook'u YÃ¼kle:**
   - File â†’ Upload notebook
   - `src/03_bert_transformer.ipynb` dosyasÄ±nÄ± seÃ§in

3. **GPU'yu AktifleÅŸtir:**
   - Runtime â†’ Change runtime type
   - Hardware accelerator â†’ **GPU**
   - Save

4. **Veriyi YÃ¼kle:**
   ```python
   # Ä°lk hÃ¼creye ekle:
   from google.colab import files
   uploaded = files.upload()  # cleaned_data.csv'yi yÃ¼kle
   ```

5. **Ã‡alÄ±ÅŸtÄ±r:**
   - Runtime â†’ Run all

---

## âš™ï¸ EÄŸitim Parametreleri

### VarsayÄ±lan Ayarlar:
```python
MAX_LENGTH = 128        # Metin uzunluÄŸu
BATCH_SIZE = 16         # Her adÄ±mda iÅŸlenen Ã¶rnek sayÄ±sÄ±
EPOCHS = 3              # EÄŸitim dÃ¶ngÃ¼sÃ¼ sayÄ±sÄ±
LEARNING_RATE = 2e-5    # Ã–ÄŸrenme hÄ±zÄ±
```

### GPU Memory DÃ¼ÅŸÃ¼kse:
```python
BATCH_SIZE = 8   # veya 4
MAX_LENGTH = 64  # daha kÄ±sa metinler
```

### Daha Ä°yi SonuÃ§ Ä°Ã§in:
```python
EPOCHS = 5       # Daha fazla eÄŸitim
BATCH_SIZE = 32  # Daha bÃ¼yÃ¼k batch (GPU yeterliyse)
```

---

## ğŸ“Š Beklenen SonuÃ§lar

### EÄŸitim SÃ¼resi:
- **CPU:** ~8-12 saat âš ï¸ (Ã‡OK YAVAÅ!)
- **GPU (Google Colab):** ~2-3 saat âœ…
- **High-end GPU:** ~30-60 dakika âš¡

### Beklenen Accuracy:
- **Epoch 1:** ~85-88%
- **Epoch 2:** ~88-91%
- **Epoch 3:** ~90-93% ğŸ¯

### Memory KullanÄ±mÄ±:
- **CPU:** ~4-8 GB RAM
- **GPU:** ~4-6 GB VRAM
- **Colab Free:** Yeterli (12 GB VRAM)

---

## ğŸ¯ EÄŸitim SÄ±rasÄ±nda

### Ä°lerlemeyi Takip Edin:
```
Epoch 1/3
----------------------------------------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2392/2392 [45:23<00:00, 0.88it/s, loss=0.2341]
Train Loss: 0.2341 | Train Acc: 0.9123 (91.23%)
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 299/299 [03:12<00:00, 1.56it/s]
Val Loss: 0.1823 | Val Acc: 0.9287 (92.87%)
âœ“ Model saved! Best Val Acc: 0.9287 (92.87%)
```

### Sorun YaÅŸarsanÄ±z:

#### "CUDA out of memory"
```python
# Batch size'Ä± kÃ¼Ã§Ã¼lt:
BATCH_SIZE = 8  # veya 4
```

#### "Too slow on CPU"
- Google Colab kullanÄ±n (Ã¼cretsiz GPU)
- Veya cloud GPU servisleri (AWS, Azure)

#### "Model not improving"
- Learning rate'i ayarlayÄ±n: `LEARNING_RATE = 1e-5`
- Daha fazla epoch: `EPOCHS = 5`

---

## ğŸ’¾ OluÅŸturulacak Dosyalar

EÄŸitim sonunda:
```
models/
â”œâ”€â”€ bert_model.pt                  â† Ana model (400+ MB)
â”œâ”€â”€ bert_training_history.pkl      â† EÄŸitim grafiÄŸi
â””â”€â”€ bert_tokenizer/                â† BERT tokenizer
    â”œâ”€â”€ config.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ vocab.txt
```

---

## ğŸ§ª EÄŸitim SonrasÄ± Test

### 1. Model PerformansÄ±nÄ± Kontrol Et:
```bash
python src/evaluate_current_models.py
```

Åimdi BERT de dahil olacak!

### 2. TÃ¼m Modelleri KarÅŸÄ±laÅŸtÄ±r:
```bash
jupyter notebook src/08_quick_evaluation.ipynb
```

### 3. Production API'de Kullan:
API'yi gÃ¼ncelleyip BERT endpoint'i ekleyebilirsiniz.

---

## ğŸ“ˆ Model KarÅŸÄ±laÅŸtÄ±rmasÄ± (Beklenen)

```
Model              | Accuracy | Ä°yileÅŸtirme
-------------------|----------|-------------
Baseline           | 86.04%   | Referans
LSTM               | 87.00%   | +0.96%
Ensemble           | 88.40%   | +2.36%
BERT (Beklenen)    | 90-93%   | +4-7% ğŸ¯
```

---

## âš ï¸ Ã–nemli Notlar

1. **Ä°lk Ã§alÄ±ÅŸtÄ±rma:**
   - BERT modelini internet'ten indirecek (~400 MB)
   - Ä°lk epoch daha yavaÅŸ olabilir (cache oluÅŸturuyor)

2. **Checkpoint:**
   - Her epoch sonunda en iyi model kaydedilir
   - EÄŸitim kesilirse en son kaydedilen model kullanÄ±lÄ±r

3. **Overfitting:**
   - Val accuracy dÃ¼ÅŸmeye baÅŸlarsa durdurun
   - 3 epoch genelde yeterli

4. **Results:**
   - Test accuracy > 90% hedefimiz
   - Her sÄ±nÄ±f iÃ§in F1-score > 0.85 ideal

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### En Basit Yol (Python Script):
```bash
# 1. Script'i Ã§alÄ±ÅŸtÄ±r
python src/train_bert.py

# 2. Bekle (~2-3 saat GPU ile)

# 3. SonuÃ§larÄ± gÃ¶r
# Test Accuracy: 91.23% (Ã¶rnek)

# 4. Modeli kullan
python src/06_inference_api.py
```

### Google Colab ile (Ã–nerilen - GPU Yoksa):
1. https://colab.research.google.com adresine git
2. `03_bert_transformer.ipynb` dosyasÄ±nÄ± yÃ¼kle
3. Runtime â†’ Change runtime â†’ GPU
4. Runtime â†’ Run all
5. Bekle (~2-3 saat)
6. Model'i indir ve `models/` klasÃ¶rÃ¼ne koy

---

## âœ… BaÅŸarÄ± Kriterleri

EÄŸitim baÅŸarÄ±lÄ± sayÄ±lÄ±r:
- âœ… Test Accuracy > 90%
- âœ… Val Accuracy ile Test Accuracy arasÄ± fark < 2%
- âœ… TÃ¼m sÄ±nÄ±flar iÃ§in F1-score > 0.80
- âœ… Model dosyasÄ± oluÅŸturuldu

---

## ğŸ†˜ YardÄ±m

Sorun yaÅŸarsanÄ±z:
1. GPU kullandÄ±ÄŸÄ±nÄ±zdan emin olun
2. Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n
3. Google Colab deneyin
4. `BERT_EGITIM_SORUNLARI.md` dosyasÄ±na bakÄ±n

---

**HazÄ±rsÄ±nÄ±z! Åimdi modelinizi eÄŸitin! ğŸš€**

**Tahmini SÃ¼re:** 2-3 saat (GPU ile)  
**Beklenen SonuÃ§:** %90-93 accuracy  
**Zorluk:** Orta (GPU gerekli)


