# ğŸ¤– KULLANILAN MODELLER - DETAYLI AÃ‡IKLAMA

## Model 1: Baseline - TF-IDF + Logistic Regression

### ğŸ¯ Neden KullandÄ±k?
**"Ã–nce basit bir ÅŸeyle baÅŸlayalÄ±m, ne kadar baÅŸarÄ±lÄ± olacaÄŸÄ±mÄ±zÄ± gÃ¶relim"**

Bu her makine Ã¶ÄŸrenmesi projesinin ilk adÄ±mÄ±dÄ±r. KarmaÅŸÄ±k modellere geÃ§meden Ã¶nce basit bir model ile referans noktasÄ± belirleriz.

### ğŸ“š NasÄ±l Ã‡alÄ±ÅŸÄ±r?

#### TF-IDF (Term Frequency - Inverse Document Frequency):
Metni sayÄ±lara Ã§evirir, ama akÄ±llÄ±ca:

**Ã–rnek:**
```
Ticket 1: "I need access to database"
Ticket 2: "Database access required"
```

TF-IDF her kelimeye Ã¶nem derecesi verir:
- "database" â†’ Ã–nemli (az geÃ§iyor, ayÄ±rt edici)
- "need" â†’ Az Ã¶nemli (Ã§ok geÃ§iyor, genel bir kelime)
- "access" â†’ Ã‡ok Ã¶nemli (bu kategoriye Ã¶zgÃ¼)

#### Logistic Regression:
Basit ama gÃ¼Ã§lÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ±. Her kelime kombinasyonuna bakÄ±p "Bu hangi kategoriye ait?" diye karar verir.

### âœ… AvantajlarÄ±:
1. **Ã‡OK HIZLI:** 5 dakikada eÄŸitilir
2. **AÃ‡IKLANIR:** Hangi kelimeler Ã¶nemli gÃ¶rebilirsiniz
3. **AZ KAYNAK:** Normal laptop yeterli
4. **Ä°YÄ° REFERANS:** Daha karmaÅŸÄ±k modelleri bununla karÅŸÄ±laÅŸtÄ±rÄ±rÄ±z
5. **STABIL:** Overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) riski dÃ¼ÅŸÃ¼k

### âŒ DezavantajlarÄ±:
1. Kelime sÄ±rasÄ±nÄ± anlamaz ("not good" = "good not")
2. BaÄŸlamÄ± kaÃ§Ä±rÄ±r
3. Anlamsal benzerliÄŸi gÃ¶remez ("car" ve "automobile" farklÄ± kelimeler sanÄ±r)

### ğŸ“Š SonuÃ§:
**%86.04 accuracy** - Gayet iyi bir baÅŸlangÄ±Ã§!

---

## Model 2: LSTM - Word2Vec + Bidirectional LSTM

### ğŸ¯ Neden KullandÄ±k?
**"Kelimelerin sÄ±rasÄ±nÄ± ve baÄŸlamÄ±nÄ± anlayan bir model kullanalÄ±m"**

Baseline iyi ama kelime sÄ±rasÄ±nÄ± anlamÄ±yor. LSTM bunu Ã§Ã¶zer.

### ğŸ“š NasÄ±l Ã‡alÄ±ÅŸÄ±r?

#### 1. Word2Vec (Kelime GÃ¶mme):
Kelimeleri anlamsal vektÃ¶rlere Ã§evirir.

**Sihir burada:**
```
"king" - "man" + "woman" â‰ˆ "queen"
"car" â‰ˆ "automobile" (benzer vektÃ¶rler)
```

Her kelime 200 boyutlu bir vektÃ¶r olur. Benzer anlamlÄ± kelimeler yakÄ±n vektÃ¶rlere sahip olur.

#### 2. LSTM (Long Short-Term Memory):
Metni sÄ±rayla okur ve **hafÄ±zasÄ±** vardÄ±r!

**Ã–rnek:**
```
"I don't need access" â† "don't" kelimesi anlamÄ± deÄŸiÅŸtirir
"I need access" â† FarklÄ± anlam
```

LSTM bu farkÄ± anlar Ã§Ã¼nkÃ¼ kelimeleri sÄ±rayla iÅŸler ve Ã¶nceki kelimeleri hatÄ±rlar.

#### 3. Bidirectional (Ä°ki YÃ¶nlÃ¼):
Metni hem soldan saÄŸa, hem saÄŸdan sola okur.

```
"need access to database for project"
â†’ Ä°leri: need â†’ access â†’ to â†’ database
â† Geri: project â†’ for â†’ database â†’ to
```

Ä°ki yÃ¶nden de bakarak daha iyi anlar.

### âœ… AvantajlarÄ±:
1. **BAÄLAM ANLAMA:** Kelime sÄ±rasÄ±nÄ± ve iliÅŸkilerini anlar
2. **ANLAMsal BENZERLÄ°K:** "car" ve "automobile" aynÄ± ÅŸey olduÄŸunu bilir
3. **DERÄ°N Ã–ÄRENME:** KarmaÅŸÄ±k kalÄ±plarÄ± yakalar
4. **UZUN METÄ°NLER:** Uzun cÃ¼mleler iÃ§in iyidir

### âŒ DezavantajlarÄ±:
1. **YAVAÅ:** EÄŸitim ~30 dakika
2. **KARMAÅIK:** Daha fazla parametre, ayar gerekir
3. **KAYNAK:** GPU tercih edilir
4. **OVERFÄ°TTÄ°NG RÄ°SKÄ°:** AÅŸÄ±rÄ± ezberleme olabilir

### ğŸ“Š SonuÃ§:
**%87.00 accuracy** - Baseline'dan %0.96 daha iyi!

---

## Model 3: Ensemble - Baseline + LSTM BirleÅŸimi

### ğŸ¯ Neden KullandÄ±k?
**"Ä°ki modelin gÃ¼Ã§lÃ¼ yÃ¶nlerini birleÅŸtirelim"**

Bazen bir model bir ÅŸeyi iyi yapar, baÅŸka model baÅŸka ÅŸeyi. Ä°kisini birleÅŸtirince daha iyi sonuÃ§!

### ğŸ“š NasÄ±l Ã‡alÄ±ÅŸÄ±r?

Her iki modelden tahmin alÄ±r, ortalamasÄ±nÄ± alÄ±r:

```
Yeni Ticket: "Need database access"

Baseline tahmini:
  Access: %65
  Hardware: %20
  HR: %15

LSTM tahmini:
  Access: %80
  Storage: %15
  HR: %5

Ensemble (Ortalama):
  Access: %72.5 â† EN YÃœKSEK!
  Hardware: %10
  HR: %10
  
Karar: ACCESS âœ“
```

### âœ… AvantajlarÄ±:
1. **DAHA DOÄRU:** Her iki modelin gÃ¼cÃ¼nÃ¼ kullanÄ±r
2. **DAHA GÃœVENÄ°LÄ°R:** Tek model hata yapsa, diÄŸeri dengeler
3. **KOLAY:** Sadece tahminleri birleÅŸtirir
4. **HIZLI:** EÄŸitim gerektirmez, var olan modelleri kullanÄ±r

### âŒ DezavantajlarÄ±:
1. **2 MODEL GEREKÄ°R:** Hem Baseline hem LSTM Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±
2. **YAVAÅ TAHMÄ°N:** Ä°ki model de Ã§alÄ±ÅŸÄ±r (2x zaman)
3. **KARMAÅIK DEPLOYMENT:** Ä°ki modeli birlikte sunmak gerek

### ğŸ“Š SonuÃ§:
**%88.40 accuracy** - LSTM'den %1.40 daha iyi!

---

## Model 4: BERT - Transfer Learning (Fine-Tuning)

### ğŸ¯ Neden KullandÄ±k?
**"DÃ¼nyanÄ±n en geliÅŸmiÅŸ NLP modelini kullanalÄ±m!"**

BERT, Google tarafÄ±ndan milyarlarca kelime ile eÄŸitilmiÅŸ. Biz onu bizim veriye "uyarlÄ±yoruz" (fine-tune).

### ğŸ“š NasÄ±l Ã‡alÄ±ÅŸÄ±r?

#### Pre-trained Model:
BERT Ã¶nceden Wikipedia, kitaplar, haberler gibi dev verilerle eÄŸitilmiÅŸ. Ä°ngilizce'yi Ã§ok iyi anlÄ±yor.

#### Transfer Learning:
```
Google'Ä±n BERT'i (milyarlarca kelime ile eÄŸitilmiÅŸ)
         â†“
Bizim verilerimizle ince ayar (fine-tune)
         â†“
Ticket sÄ±nÄ±flandÄ±rma uzmanÄ± BERT!
```

#### Attention Mechanism (Dikkat MekanizmasÄ±):
BERT her kelimenin diÄŸer tÃ¼m kelimelerle iliÅŸkisine bakar.

**Ã–rnek:**
```
"I need access to the database for the project"

BERT analiz eder:
- "access" + "database" = Birlikte Ã¶nemli!
- "access" + "project" = Ä°liÅŸki var!
- "the" = Ã–nemsiz
```

Her kelimenin baÄŸlamdaki Ã¶nemini anlar.

### âœ… AvantajlarÄ±:
1. **EN YÃœKSEK PERFORMANS:** State-of-the-art sonuÃ§lar
2. **DERÄ°N ANLAMA:** BaÄŸlamÄ± tam kavrar
3. **TRANSFER LEARNING:** Milyarlarca kelimenin bilgisi
4. **Ã‡OK YÃ–NLÃœ BAÄLAM:** Her kelimenin tÃ¼m kelimelerle iliÅŸkisi
5. **ROBUST:** FarklÄ± yazÄ±m stillerine dayanÄ±klÄ±

### âŒ DezavantajlarÄ±:
1. **Ã‡OK YAVAÅ:** EÄŸitim ~2-3 saat (GPU ile!)
2. **BÃœYÃœK MODEL:** ~400 MB dosya boyutu
3. **GPU GEREKÄ°R:** CPU'da Ã§ok yavaÅŸ
4. **KARMAÅIK:** Anlama ve debug etme zor
5. **KAYNAK AÃ‡LIÄI:** RAM ve GPU memory gerekir

### ğŸ“Š SonuÃ§:
**%88.82 accuracy** - EN Ä°YÄ° MODEL! ğŸ†

---

## ğŸ“Š MODELLER ARASI KARÅILAÅTIRMA

### HÄ±z KarÅŸÄ±laÅŸtÄ±rmasÄ±:
```
Baseline:  EÄŸitim: 5 dk    | Tahmin: 0.01 sn  âš¡âš¡âš¡
LSTM:      EÄŸitim: 30 dk   | Tahmin: 0.05 sn  âš¡âš¡
Ensemble:  EÄŸitim: 0 dk    | Tahmin: 0.06 sn  âš¡âš¡
BERT:      EÄŸitim: 150 dk  | Tahmin: 0.10 sn  âš¡
```

### DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±:
```
Baseline:  86.04%  â­â­â­
LSTM:      87.00%  â­â­â­â­
Ensemble:  88.40%  â­â­â­â­
BERT:      88.82%  â­â­â­â­â­
```

### Kaynak Ä°htiyacÄ±:
```
Baseline:  CPU yeterli     ğŸ’»
LSTM:      GPU tercih      ğŸ’»ğŸ®
Ensemble:  CPU yeterli     ğŸ’»
BERT:      GPU ÅŸart!       ğŸ®ğŸ®ğŸ®
```

---

## ğŸ¯ HOCAYA ANLATIM - MODEL BAZINDA

### Model 1: Baseline
> **"Hocam, Ã¶nce basit bir yÃ¶ntemle baÅŸladÄ±m. TF-IDF ile metni sayÄ±sal vektÃ¶rlere Ã§evirdim ve Logistic Regression ile sÄ±nÄ±flandÄ±rdÄ±m. Bu bana %86 doÄŸruluk verdi ve referans noktamÄ± oluÅŸturdu."**

### Model 2: LSTM
> **"Sonra derin Ã¶ÄŸrenme kullandÄ±m. Word2Vec ile kelimeleri anlamsal vektÃ¶rlere Ã§evirdim. Bidirectional LSTM ile metni iki yÃ¶nden okuyarak kelime sÄ±rasÄ± ve baÄŸlamÄ± Ã¶ÄŸrendim. Bu %87'ye Ã§Ä±kardÄ±."**

### Model 3: Ensemble
> **"Ä°ki modelin tahminlerini birleÅŸtirerek ensemble yaptÄ±m. Her iki modelin gÃ¼Ã§lÃ¼ yÃ¶nlerini kullanarak %88.4'e ulaÅŸtÄ±m."**

### Model 4: BERT
> **"Son olarak Google'Ä±n pre-trained BERT modelini kullandÄ±m. Transfer learning ile milyarlarca kelime ile eÄŸitilmiÅŸ modeli bizim veriye uyarladÄ±m. GPU ile fine-tune ederek %88.82'ye ulaÅŸtÄ±m. Bu en iyi sonucumuz oldu."**

---

## ğŸ’¡ NEDEN 4 MODEL?

### Bilimsel YaklaÅŸÄ±m:
1. **Baseline:** KarÅŸÄ±laÅŸtÄ±rma referansÄ±
2. **LSTM:** Derin Ã¶ÄŸrenme gÃ¼cÃ¼nÃ¼ gÃ¶rmek
3. **Ensemble:** BirleÅŸtirme tekniklerini denemek
4. **BERT:** State-of-the-art sonuÃ§lara ulaÅŸmak

### Hocaya GÃ¶steriyor ki:
- âœ… FarklÄ± yaklaÅŸÄ±mlarÄ± biliyorsunuz
- âœ… KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz yapabiliyorsunuz
- âœ… Klasikten moderne tÃ¼m teknikleri kullanÄ±yorsunuz
- âœ… Transfer learning kavramÄ±nÄ± anlÄ±yorsunuz

---

## ğŸ“ HOCAYA TEK PARAGRAFTA Ã–Z Ã–ZET:

> **"Projemde 47 bin IT destek talebini 8 kategoriye sÄ±nÄ±flandÄ±ran bir sistem geliÅŸtirdim. 
> 
> 4 farklÄ± yaklaÅŸÄ±m denedim:
> 
> 1. **Baseline** olarak TF-IDF ile kelime sÄ±klÄ±klarÄ±nÄ± Ã§Ä±karÄ±p Logistic Regression ile sÄ±nÄ±flandÄ±rdÄ±m (%86). Bu hÄ±zlÄ± ve basit bir yÃ¶ntemdi.
> 
> 2. **Derin Ã¶ÄŸrenme** iÃ§in Word2Vec ile kelimeleri vektÃ¶rlere Ã§evirip Bidirectional LSTM kullandÄ±m (%87). LSTM kelime sÄ±rasÄ±nÄ± ve baÄŸlamÄ± anladÄ±.
> 
> 3. **Ensemble** yÃ¶ntemiyle bu iki modeli birleÅŸtirip daha gÃ¼venilir sonuÃ§lar aldÄ±m (%88.4).
> 
> 4. Son olarak **transfer learning** ile Google'Ä±n BERT modelini fine-tune ettim (%88.82). BERT milyarlarca kelime ile Ã¶nceden eÄŸitilmiÅŸ olduÄŸundan en iyi sonucu verdi.
> 
> TÃ¼m modeller GPU ile optimize edildi ve production-ready REST API olarak sunulabilir durumda."**

---

Bu aÃ§Ä±klama yeter mi yoksa daha detaylÄ± anlatmamÄ± ister misiniz? ğŸ˜Š

